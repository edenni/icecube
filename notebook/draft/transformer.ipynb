{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import logging\n",
    "from math import sqrt\n",
    "from typing import Callable\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pytorch_lightning import LightningModule\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "from icecube.metrics.angle import MeanAngularError\n",
    "from icecube.utils.coordinate import (\n",
    "    bins2angles,\n",
    "    create_angle_bins,\n",
    "    create_bins,\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class TransformerEncoder(torch.nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, dropout, feedforward_dim):\n",
    "        super().__init__()\n",
    "        self.attn = torch.nn.MultiheadAttention(\n",
    "            embed_dim, num_heads, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.linear_1 = torch.nn.Linear(embed_dim, feedforward_dim)\n",
    "        self.linear_2 = torch.nn.Linear(feedforward_dim, embed_dim)\n",
    "        self.layernorm_1 = torch.nn.LayerNorm(embed_dim)\n",
    "        self.layernorm_2 = torch.nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, x_in):\n",
    "        attn_out, _ = self.attn(x_in, x_in, x_in)\n",
    "        x = self.layernorm_1(x_in + attn_out)\n",
    "        ff_out = self.linear_2(torch.nn.functional.relu(self.linear_1(x)))\n",
    "        x = self.layernorm_2(x + ff_out)\n",
    "        return x\n",
    "\n",
    "\n",
    "class TransformerAutoEncoder(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_inputs,\n",
    "        num_subspaces=8,\n",
    "        embed_dim=128,\n",
    "        num_heads=8,\n",
    "        dropout=0,\n",
    "        feedforward_dim=512,\n",
    "        emphasis=0.75,\n",
    "        mask_loss_weight=2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_subspaces = num_subspaces\n",
    "        self.num_heads = num_heads\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        self.stem = nn.Linear(in_features=num_inputs, out_features=embed_dim)\n",
    "\n",
    "        self.encoder_1 = TransformerEncoder(\n",
    "            embed_dim, num_heads, dropout, feedforward_dim\n",
    "        )\n",
    "        self.encoder_2 = TransformerEncoder(\n",
    "            embed_dim, num_heads, dropout, feedforward_dim\n",
    "        )\n",
    "        self.encoder_3 = TransformerEncoder(\n",
    "            embed_dim, num_heads, dropout, feedforward_dim\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.relu(self.stem(x))\n",
    "\n",
    "        x1 = self.encoder_1(x)\n",
    "        x2 = self.encoder_2(x1)\n",
    "        x3 = self.encoder_3(x2)\n",
    "\n",
    "        return torch.concat([x1, x2, x3], dim=-1)\n",
    "\n",
    "\n",
    "class AddPositionalEncoding(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embed_dim: int,\n",
    "        max_time: int,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.max_time = max_time\n",
    "        positional_encoding_weight: torch.Tensor = self._initialize_weight()\n",
    "        self.register_buffer(\n",
    "            \"positional_encoding_weight\", positional_encoding_weight\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        seq_len = x.size(1)\n",
    "        return x + self.positional_encoding_weight[:seq_len, :].unsqueeze(0)\n",
    "\n",
    "    def _get_positional_encoding(self, pos: int, i: int) -> float:\n",
    "        w = pos / (10000 ** (((2 * i) // 2) / self.embed_dim))\n",
    "        if i % 2 == 0:\n",
    "            return np.sin(w)\n",
    "        else:\n",
    "            return np.cos(w)\n",
    "\n",
    "    def _initialize_weight(self) -> torch.Tensor:\n",
    "        positional_encoding_weight = [\n",
    "            [\n",
    "                self._get_positional_encoding(pos, i)\n",
    "                for i in range(1, self.embed_dim + 1)\n",
    "            ]\n",
    "            for pos in range(1, self.max_time + 1)\n",
    "        ]\n",
    "        return torch.tensor(positional_encoding_weight).float()\n",
    "\n",
    "\n",
    "class TransformerClassifier(LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int,\n",
    "        embed_dim: int,\n",
    "        output_size: int,\n",
    "        nhead: int,\n",
    "        feedforward_dim: int,\n",
    "        batch_first: bool = True,\n",
    "        dropout: float = 0.1,\n",
    "        task: str = \"rgr\",\n",
    "        optimizer: Callable = None,\n",
    "        scheduler: Callable = None,\n",
    "        criterion: nn.Module = None,\n",
    "    ):\n",
    "        super(TransformerClassifier, self).__init__()\n",
    "        self.save_hyperparameters(ignore=[\"criterion\"])\n",
    "        self.num_bins = int(sqrt(output_size))\n",
    "\n",
    "        self.transformer = TransformerAutoEncoder(\n",
    "            num_inputs=input_size,\n",
    "            embed_dim=embed_dim,\n",
    "            num_heads=nhead,\n",
    "            dropout=dropout,\n",
    "            feedforward_dim=feedforward_dim,\n",
    "        )\n",
    "\n",
    "        # TODO: create multiple fc layers\n",
    "        self.linear = nn.Linear(3 * embed_dim * 128, output_size)\n",
    "\n",
    "        # TODO: build criterion from config\n",
    "        self.criterion = criterion\n",
    "\n",
    "        # Metircs\n",
    "        self.mae = MeanAngularError()\n",
    "\n",
    "        # Create bins\n",
    "        if self.hparams.task == \"clf\":\n",
    "            self.acc = Accuracy(task=\"multiclass\", num_classes=output_size)\n",
    "            azimuth_bins, zenith_bins = create_bins(self.num_bins)\n",
    "            azimuth_bins = torch.as_tensor(azimuth_bins)\n",
    "            zenith_bins = torch.as_tensor(zenith_bins)\n",
    "\n",
    "            self.angle_bins = torch.as_tensor(\n",
    "                create_angle_bins(azimuth_bins, zenith_bins, self.num_bins)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.transformer(x)\n",
    "        x = x.flatten(1)\n",
    "        y_pred = self.linear(x)\n",
    "        return y_pred\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        if self.hparams.task == \"clf\":\n",
    "            x, _, y = batch\n",
    "        elif self.hparams.task == \"rgr\":\n",
    "            x, y, _ = batch\n",
    "\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"train/loss\", loss, on_step=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y, y_oh = batch\n",
    "        y_hat = self(x)\n",
    "\n",
    "        if self.hparams.task == \"clf\":\n",
    "            loss = self.criterion(y_hat, y_oh)\n",
    "        elif self.hparams.task == \"rgr\":\n",
    "            loss = self.criterion(y_hat, y)\n",
    "\n",
    "        self.log(\"val/loss\", loss)\n",
    "\n",
    "        if self.hparams.task == \"clf\":\n",
    "            self.acc(y_hat, y_oh)\n",
    "\n",
    "            azimuth, zenith = bins2angles(\n",
    "                y_hat, self.angle_bins, self.num_bins\n",
    "            )\n",
    "            y_hat = torch.stack([azimuth, zenith], axis=-1)\n",
    "\n",
    "        self.mae(y_hat, y)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def on_validation_start(self) -> None:\n",
    "        if (\n",
    "            self.hparams.task == \"clf\"\n",
    "            and self.angle_bins.device != self.device\n",
    "        ):\n",
    "            logger.info(\n",
    "                f\"Start validation. Move angle bin vertors to <{self.device}>\"\n",
    "            )\n",
    "            self.angle_bins = self.angle_bins.to(self.device)\n",
    "\n",
    "    def on_validation_epoch_end(self) -> None:\n",
    "        if self.hparams.task == \"clf\":\n",
    "            acc = self.acc.compute()\n",
    "            self.log(\"val/acc\", acc)\n",
    "        mae = self.mae.compute()\n",
    "        self.log(\"val/mae\", mae, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = self.hparams.optimizer(params=self.parameters())\n",
    "\n",
    "        if self.hparams.scheduler is not None:\n",
    "            scheduler = self.hparams.scheduler(optimizer=optimizer)\n",
    "            return {\n",
    "                \"optimizer\": optimizer,\n",
    "                \"lr_scheduler\": {\n",
    "                    \"scheduler\": scheduler,\n",
    "                    \"monitor\": \"val/loss\",\n",
    "                    \"interval\": \"epoch\",\n",
    "                    \"frequency\": 1,\n",
    "                },\n",
    "            }\n",
    "        return {\"optimizer\": optimizer}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 32, 128])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe = AddPositionalEncoding(128, 10000)\n",
    "\n",
    "x = torch.randn(16, 32, 128)\n",
    "\n",
    "pe(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = TransformerAutoEncoder(9, 64, 64, 4, 0.1, 256)\n",
    "linear = nn.Linear(3 * 64, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanAngularError(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, az_true: torch.Tensor, zen_true: torch.Tensor, az_pred, zen_pred):\n",
    "        if not (\n",
    "            torch.all(torch.isfinite(az_true))\n",
    "            and torch.all(torch.isfinite(zen_true))\n",
    "            and torch.all(torch.isfinite(az_pred))\n",
    "            and torch.all(torch.isfinite(zen_pred))\n",
    "        ):\n",
    "            raise ValueError(\"All arguments must be finite\")\n",
    "\n",
    "        # pre-compute all sine and cosine values\n",
    "        sa1 = az_true.sin()\n",
    "        ca1 = az_true.cos()\n",
    "        sz1 = zen_true.sin()\n",
    "        cz1 = zen_true.cos()\n",
    "\n",
    "        sa2 = az_pred.sin()\n",
    "        ca2 = az_pred.cos()\n",
    "        sz2 = zen_pred.sin()\n",
    "        cz2 = zen_pred.cos()\n",
    "\n",
    "        # scalar product of the two cartesian vectors (x = sz*ca, y = sz*sa, z = cz)\n",
    "        scalar_prod = sz1 * sz2 * (ca1 * ca2 + sa1 * sa2) + (cz1 * cz2)\n",
    "\n",
    "        # scalar product of two unit vectors is always between -1 and 1, this is against nummerical instability\n",
    "        # that might otherwise occure from the finite precision of the sine and cosine functions\n",
    "        scalar_prod = torch.clip(scalar_prod, -1, 1)\n",
    "\n",
    "        ae = scalar_prod.arccos().abs()\n",
    "\n",
    "        # convert back to an angle (in radian)\n",
    "        return ae.mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "creiterion = MeanAngularError()\n",
    "preds = torch.randn(14, 2, requires_grad=True)\n",
    "target = torch.randn(14, 2, requires_grad=True)\n",
    "\n",
    "az_true = target[:, 0]\n",
    "zen_true = target[:, 1]\n",
    "az_pred = preds[:, 0]\n",
    "zen_pred = preds[:, 1]\n",
    "# az_true = torch.randn(14, 1, requires_grad=True)\n",
    "# zen_true = torch.randn(14, 1, requires_grad=True)\n",
    "# az_pred = torch.randn(14, 1, requires_grad=True)\n",
    "# zen_pred = torch.randn(14, 1, requires_grad=True)\n",
    "\n",
    "loss = creiterion(az_pred, zen_pred, az_true, zen_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0385,  0.0565],\n",
      "        [ 0.0035,  0.0691],\n",
      "        [ 0.0065,  0.0702],\n",
      "        [-0.0020, -0.0702],\n",
      "        [ 0.0017,  0.0704],\n",
      "        [-0.0016, -0.0501],\n",
      "        [-0.0078,  0.0709],\n",
      "        [ 0.0201, -0.0429],\n",
      "        [-0.0130, -0.0677],\n",
      "        [-0.0019, -0.0319],\n",
      "        [ 0.0501, -0.0073],\n",
      "        [ 0.0346, -0.0187],\n",
      "        [-0.0213, -0.0352],\n",
      "        [ 0.0140, -0.0653]])\n"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "print(preds.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.5533, 1.2520, 0.9543, 1.8697, 1.9385, 1.4203, 1.7749, 1.6796, 1.9513,\n",
       "        1.6815, 1.9529, 0.7545, 1.3417, 2.5309, 2.0548, 2.9175, 1.3568, 0.8841,\n",
       "        1.5042, 0.9026])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.randn(20, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.5533, 1.2520, 0.9543, 1.8697, 1.9385, 1.4203, 1.7749, 1.6796, 1.9513,\n",
      "        1.6815, 1.9529, 0.7545, 1.3417, 2.5309, 2.0548, 2.9175, 1.3568, 0.8841,\n",
      "        1.5042, 0.9026])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(2.5533)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = torch.linalg.vector_norm(x, dim=-1, keepdim=True)\n",
    "print(torch.linalg.norm(x, dim=-1))\n",
    "torch.sqrt(x[0, 0]**2 + x[0, 1]**2 + x[0, 2]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linalg.vector_norm(x/r, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icecube",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5d1f5c8a913c9cf5c53f678b20c057b673b014e2f0c3fa6d6f65aab94461faf8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
