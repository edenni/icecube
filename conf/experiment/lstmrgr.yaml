# @package _global_

# to execute this experiment run:
# python train.py experiment=example

defaults:
  - override /data: event.yaml
  - override /model: lstmrgr.yaml
  - override /callbacks: default.yaml
  - override /trainer: default.yaml
  - override /logger: wandb
  - override /model/criterion: mse

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

hydra:
  job:
    name: pointpicker_lstm

trainer:
  max_epochs: 500

callbacks:
  early_stopping:
    monitor: val/mae
    patience: 20
    mode: min
    min_delta: 0.001
  model_checkpoint:
    monitor: val/mae
    mode: min

data:
  batch_size: 1024
  shift_azimuth: true

model:
  num_layers: 2
  bidirectional: true
  bias: true

  optimizer:
    lr: 1e-3
    weight_decay: 1e-5
  scheduler:
    patience: 5


logger:
  project: icecube
  name: pointpicker_lstm_rgr_batch_51_74_bi_bias_shift
  group: 
  log_model: true

# train
train: true
cv: null
fold: null